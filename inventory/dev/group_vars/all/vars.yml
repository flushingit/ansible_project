---

# "Check system" variables

os_valid_distributions:
  - RedHat
  - CentOS
  - Rocky

os_minimum_versions:
  RedHat: 7
  CentOS: 7
  Rocky: 8.4

architecture : linux_amd64
systemd_unitdir: /usr/lib/systemd/system

# Packages to install

packages:
  - epel-release
  - curl
  - gdisk
  - vim
  - net-tools
  - tcpdump
  - traceroute
  - telnet
  - wget
  - bind-utils
  - gzip
  - tar
  - unzip
  - gcc
  - python3-devel
  - python3-pip
  - python2
  - python3-libselinux
  - python3-libsemanage
  - python3-policycoreutils
  - jq

# Logrotate variables

logrotate:
  owner: root
  group: root
  dir: /etc/logrotate.d

# Chrony settings

timezone: "Europe/Moscow"

ntp:
  servers:
    - pool.ntp.org
    - 1.ru.pool.ntp.org
    - 2.ru.pool.ntp.org

# Firewall Settings

firewall:
  ports:
    - 22/tcp
    - 80/tcp
    - 443/tcp
    - 5432/tcp
    - 8008/tcp
    - 8300/tcp
    - 8301/tcp
    - 8301/udp
    - 8302/tcp
    - 8302/udp
    - 8500/tcp
    - 8502/tcp
    - 8600/tcp
    - 8600/udp
    - 9100/tcp

  services:
    - http
    - https

# Consul settings

consul_server_defaults:
  service: "consul.service"

consul_agent_defaults:
  service: "consul.service"

consul:
  user: consul
  group: consul
  bin_sources: /usr/bin
  config_dir: /etc/consul.d
  data_dir: /home/consul
  service_dir: /home/consul/services
  version: 1.12.0
  key: CzmvZMSgNXMr0mJHh1Z98w==

# PostgreSQL variables
postgresql_version: "14"
# postgresql_data_dir: see vars/Debian.yml or vars/RedHat.yml
postgresql_port: "5432"
postgresql_encoding: "UTF8"  # for bootstrap only (initdb)
postgresql_locale: "en_US.UTF-8"  # for bootstrap only (initdb)
postgresql_data_checksums: true  # for bootstrap only (initdb)
postgresql_password_encryption_algorithm: "scram-sha-256"  # or "md5" if your clients do not work with passwords encrypted with SCRAM-SHA-256

# (optional) list of users to be created (if not already exists)
postgresql_users:
  - {name: "django_test", password: "django_test1234"}
  - {name: "django_test2", password: "django_test1234"}
  - {name: "saleor_test", password: "saleor_test1234"}

# (optional) list of databases to be created (if not already exists)
postgresql_databases:
  - {db: "testapp", encoding: "UTF8", lc_collate: "ru_RU.UTF-8", lc_ctype: "ru_RU.UTF-8", owner: "django_test"}
  - {db: "testapp2", encoding: "UTF8", lc_collate: "ru_RU.UTF-8", lc_ctype: "ru_RU.UTF-8", owner: "django_test2"}
  - {db: "saleor", encoding: "UTF8", lc_collate: "ru_RU.UTF-8", lc_ctype: "ru_RU.UTF-8", owner: "saleor"}

# (optional) list of database extensions to be created (if not already exists)
postgresql_extensions: []

# postgresql parameters to bootstrap dcs (are parameters for example)
postgresql_parameters:
  - {option: "max_connections", value: "500"}
  - {option: "superuser_reserved_connections", value: "5"}
  - {option: "password_encryption", value: "{{ postgresql_password_encryption_algorithm }}"}
  - {option: "max_locks_per_transaction", value: "64"}  # raise this value (ex. 512) if you have queries that touch many different tables (partitioning)
  - {option: "max_prepared_transactions", value: "0"}
  - {option: "huge_pages", value: "try"}  # or "on" if you set "vm_nr_hugepages" in kernel parameters
  - {option: "shared_buffers", value: "512MB"}  # please change this value
  - {option: "work_mem", value: "128MB"}  # please change this value
  - {option: "maintenance_work_mem", value: "256MB"}  # please change this value
  - {option: "effective_cache_size", value: "4GB"}  # please change this value
  - {option: "checkpoint_timeout", value: "15min"}
  - {option: "checkpoint_completion_target", value: "0.9"}
  - {option: "min_wal_size", value: "2GB"}
  - {option: "max_wal_size", value: "8GB"}  # or 16GB/32GB
  - {option: "wal_buffers", value: "32MB"}
  - {option: "default_statistics_target", value: "1000"}
  - {option: "seq_page_cost", value: "1"}
  - {option: "random_page_cost", value: "4"}  # "1.1" for SSD storage. Also, if your databases fits in shared_buffers
  - {option: "effective_io_concurrency", value: "2"}  # "200" for SSD storage
  - {option: "synchronous_commit", value: "on"}  # or 'off' if you can you lose single transactions in case of a crash
  - {option: "autovacuum", value: "on"}  # never turn off the autovacuum!
  - {option: "autovacuum_max_workers", value: "5"}
  - {option: "autovacuum_vacuum_scale_factor", value: "0.01"}  # or 0.005/0.001
  - {option: "autovacuum_analyze_scale_factor", value: "0.01"}
  - {option: "autovacuum_vacuum_cost_limit", value: "500"}  # or 1000/5000
  - {option: "autovacuum_vacuum_cost_delay", value: "2"}
  - {option: "autovacuum_naptime", value: "1s"}
  - {option: "max_files_per_process", value: "4096"}
  - {option: "archive_mode", value: "on"}
  - {option: "archive_timeout", value: "1800s"}
  - {option: "archive_command", value: "cd ."}  # not doing anything yet with WAL-s
  - {option: "wal_level", value: "replica"}
  - {option: "wal_keep_size", value: "2GB"}
  - {option: "max_wal_senders", value: "10"}
  - {option: "max_replication_slots", value: "10"}
  - {option: "hot_standby", value: "on"}
  - {option: "wal_log_hints", value: "on"}
  - {option: "wal_compression", value: "on"}
  - {option: "shared_preload_libraries", value: "pg_stat_statements,auto_explain"}
  - {option: "pg_stat_statements.max", value: "10000"}
  - {option: "pg_stat_statements.track", value: "all"}
  - {option: "pg_stat_statements.track_utility", value: "false"}
  - {option: "pg_stat_statements.save", value: "true"}
  - {option: "auto_explain.log_min_duration", value: "10s"}  # 10 sec (by default). Decrease this value if necessary
  - {option: "auto_explain.log_analyze", value: "true"}
  - {option: "auto_explain.log_buffers", value: "true"}
  - {option: "auto_explain.log_timing", value: "false"}
  - {option: "auto_explain.log_triggers", value: "true"}
  - {option: "auto_explain.log_verbose", value: "true"}
  - {option: "auto_explain.log_nested_statements", value: "true"}
  - {option: "track_io_timing", value: "on"}
  - {option: "log_lock_waits", value: "on"}
  - {option: "log_temp_files", value: "0"}
  - {option: "track_activities", value: "on"}
  - {option: "track_counts", value: "on"}
  - {option: "track_functions", value: "all"}
  - {option: "log_checkpoints", value: "on"}
  - {option: "logging_collector", value: "on"}
  - {option: "log_truncate_on_rotation", value: "on"}
  - {option: "log_rotation_age", value: "1d"}
  - {option: "log_rotation_size", value: "0"}
  - {option: "log_line_prefix", value: "'%t [%p-%l] %r %q%u@%d '"}
  - {option: "log_filename", value: "'postgresql-%a.log'"}
  - {option: "log_directory", value: "{{ postgresql_log_dir }}"}
  - {option: "hot_standby_feedback", value: "on"}  # allows feedback from a hot standby to the primary that will avoid query conflicts
  - {option: "max_standby_streaming_delay", value: "30s"}
  - {option: "wal_receiver_status_interval", value: "10s"}
  - {option: "idle_in_transaction_session_timeout", value: "10min"}  # reduce this timeout if possible
  - {option: "jit", value: "off"}

# specify additional hosts that will be added to the pg_hba.conf
postgresql_pg_hba:
  - {type: "local", database: "all", user: "postgres", address: "", method: "trust"}  # "local=trust" required for ansible modules "postgresql_(user,db,ext)"
  - {type: "local", database: "all", user: "all", address: "", method: "peer"}
  - {type: "host", database: "all", user: "all", address: "127.0.0.1/32", method: "{{ postgresql_password_encryption_algorithm }}"}
  - {type: "host", database: "all", user: "all", address: "::1/128", method: "{{ postgresql_password_encryption_algorithm }}"}

# list of lines that Patroni will use to generate pg_ident.conf
postgresql_pg_ident: []

# PgBouncer parameters
pgbouncer_install: true  # or 'false' if you do not want to install and configure the pgbouncer service
pgbouncer_conf_dir: "/etc/pgbouncer"
pgbouncer_log_dir: "/var/log/pgbouncer"
pgbouncer_listen_port: 6432
pgbouncer_max_client_conn: 10000
pgbouncer_max_db_connections: 1000
pgbouncer_default_pool_size: 20
pgbouncer_default_pool_mode: "session"
pgbouncer_generate_userlist: true  # generate the authentication file (userlist.txt) from the pg_shadow system table
pgbouncer_auth_type: "{{ postgresql_password_encryption_algorithm }}"

pgbouncer_pools:
  - {name: "postgres", dbname: "postgres", pool_parameters: ""}

# Extended variables (optional)
patroni_ttl: 30
patroni_loop_wait: 10
patroni_retry_timeout: 10
patroni_maximum_lag_on_failover: 1048576
patroni_master_start_timeout: 300


patroni_standby_cluster:
  host: ""  # an address of remote master
  port: "5432"  # a port of remote master
#  primary_slot_name: ""  # which slot on the remote master to use for replication (optional)
#  restore_command: ""  # command to restore WAL records from the remote master to standby leader (optional)
#  recovery_min_apply_delay: ""  # how long to wait before actually apply WAL records on a standby leader (optional)

patroni_log_destination: stderr  # or 'logfile'
# if patroni_log_destination: logfile
patroni_log_dir: /var/log/patroni
patroni_log_level: info
patroni_log_traceback_level: error
patroni_log_format: "%(asctime)s %(levelname)s: %(message)s"
patroni_log_dateformat: ""
patroni_log_max_queue_size: 1000
patroni_log_file_num: 4
patroni_log_file_size: 25000000  # bytes
patroni_log_loggers_patroni_postmaster: warning
patroni_log_loggers_urllib3: warning  # or 'debug'

patroni_postgresql_use_pg_rewind: true  # or 'false'
# try to use pg_rewind on the former leader when it joins cluster as a replica.

patroni_remove_data_directory_on_rewind_failure: false  # or 'true' (if use_pg_rewind: 'true')
# avoid removing the data directory on an unsuccessful rewind
# if 'true', Patroni will remove the PostgreSQL data directory and recreate the replica.

patroni_remove_data_directory_on_diverged_timelines: false  # or 'true'
# if 'true', Patroni will remove the PostgreSQL data directory and recreate the replica
# if it notices that timelines are diverging and the former master can not start streaming from the new master.

# https://patroni.readthedocs.io/en/latest/replica_bootstrap.html#bootstrap
patroni_cluster_bootstrap_method: "initdb"  # or "wal-g", "pgbackrest", "pg_probackup"

# https://patroni.readthedocs.io/en/latest/replica_bootstrap.html#building-replicas
patroni_create_replica_methods:
#  - pgbackrest
#  - wal_g
#  - pg_probackup
  - basebackup

pgbackrest:
  - {option: "command", value: "/usr/bin/pgbackrest --stanza={{ pgbackrest_stanza }} --delta restore"}
  - {option: "keep_data", value: "True"}
  - {option: "no_params", value: "True"}
wal_g:
  - {option: "command", value: "wal-g backup-fetch {{ postgresql_data_dir }} LATEST"}
  - {option: "no_params", value: "True"}
basebackup:
  - {option: "max-rate", value: "100M"}
  - {option: "checkpoint", value: "fast"}
pg_probackup:
  - {option: "command", value: "pg_probackup-{{ pg_probackup_version }} restore -B {{ pg_probackup_dir }} --instance {{ pg_probackup_instance }} -j {{ pg_probackup_threads }} {{ pg_probackup_add_keys }}"}
  - {option: "no_params", value: "true"}

# "restore_command" written to recovery.conf when configuring follower (create replica)
postgresql_restore_command: ""
# postgresql_restore_command: "wal-g wal-fetch %f %p"  # restore WAL-s using WAL-G
# postgresql_restore_command: "pgbackrest --stanza={{ pgbackrest_stanza }} archive-get %f %p"  # restore WAL-s using pgbackrest
# postgresql_restore_command: "pg_probackup-{{ pg_probackup_version }} archive-get -B {{ pg_probackup_dir }} --instance {{ pg_probackup_instance }} --wal-file-path=%p --wal-file-name=%f"  # restore WAL-s using pg_probackup

# pg_probackup
pg_probackup_install: false  # or 'true'
pg_probackup_install_from_postgrespro_repo: true  # or 'false'
pg_probackup_version: "{{ postgresql_version }}"
pg_probackup_instance: "pg_probackup_instance_name"
pg_probackup_dir: "/mnt/backup_dir"
pg_probackup_threads: "4"
pg_probackup_add_keys: "--recovery-target=latest --skip-external-dirs --no-validate"
pg_probackup_patroni_cluster_bootstrap_command: "pg_probackup-{{ pg_probackup_version }} restore -B {{ pg_probackup_dir }} --instance {{ pg_probackup_instance }} -j {{ pg_probackup_threads }} {{ pg_probackup_add_keys }}"

# WAL-G
wal_g_install: false  # or 'true'
wal_g_ver: "v0.2.19"
wal_g_json:  # more options see https://github.com/wal-g/wal-g#configuration
  - {option: "AWS_ACCESS_KEY_ID", value: "minio"}
  - {option: "AWS_SECRET_ACCESS_KEY", value: "miniosecret"}
  - {option: "AWS_ENDPOINT", value: "http://172.26.9.200:9000"}
  - {option: "WALG_S3_PREFIX", value: "s3://bucket"}
  - {option: "AWS_S3_FORCE_PATH_STYLE", value: "true"}
  - {option: "WALG_COMPRESSION_METHOD", value: "brotli"}
  - {option: "PGDATA", value: "{{ postgresql_data_dir }}"}
  - {option: "PGHOST", value: "{{ postgresql_unix_socket_dir }}"}
#  - {option: "AWS_REGION", value: "us-east-1"}
#  - {option: "WALG_S3_CA_CERT_FILE", value: "/path/to/custom/ca/file"}
#  - {option: "", value: ""}
wal_g_patroni_cluster_bootstrap_command: "wal-g backup-fetch {{ postgresql_data_dir }} LATEST"

# pgBackRest
pgbackrest_install: false  # or 'true'
pgbackrest_install_from_pgdg_repo: true  # or 'false'
pgbackrest_stanza: "stanza_name"  # specify your --stanza
pgbackrest_repo_type: "posix"  # or "s3"
pgbackrest_repo_host: "10.128.64.50"  # dedicated repository host (if repo_type: "posix")
pgbackrest_repo_user: "postgres"  # if "repo_host" is set
pgbackrest_conf_file: "/etc/pgbackrest/pgbackrest.conf"
# see more options https://pgbackrest.org/configuration.html
pgbackrest_conf:
  global:  # [global] section
    - {option: "log-level-file", value: "detail"}
    - {option: "log-path", value: "/var/log/pgbackrest"}
    - {option: "repo1-type", value: "{{ pgbackrest_repo_type |lower }}"}
    - {option: "repo1-host", value: "{{ pgbackrest_repo_host }}"}
    - {option: "repo1-host-user", value: "{{ pgbackrest_repo_user }}"}
#    - {option: "", value: ""}
  stanza:  # [stanza_name] section
    - {option: "pg1-path", value: "{{ postgresql_data_dir }}"}
    - {option: "process-max", value: "2"}
    - {option: "recovery-option", value: "recovery_target_action=promote"}
#    - {option: "", value: ""}
pgbackrest_patroni_cluster_restore_command:
  '/usr/bin/pgbackrest --stanza={{ pgbackrest_stanza }} --delta restore'  # restore from latest backup
#  '/usr/bin/pgbackrest --stanza={{ pgbackrest_stanza }} --type=time "--target=2020-06-01 11:00:00+03" --delta restore'  # Point-in-Time Recovery (example)

# PITR mode (if patroni_cluster_bootstrap_method: "pgbackrest" or "wal-g"):
# 1) The database cluster directory will be cleaned (for "wal-g") or overwritten (for "pgbackrest" --delta restore).
# 2) And also the patroni cluster "{{ patroni_cluster_name }}" will be removed from the DCS (if exist) before recovery.

disable_archive_command: true  # or 'false' to not disable archive_command after restore
keep_patroni_dynamic_json: true  # or 'false' to remove patroni.dynamic.json after restore (if exists)


# Netdata - https://github.com/netdata/netdata
netdata_install: false  # or 'true' for install Netdata on postgresql cluster nodes (with kickstart.sh)
netdata_install_options: "--stable-channel --disable-telemetry --dont-wait"
netdata_conf:
  web_bind_to: "*"
  # https://learn.netdata.cloud/docs/store/change-metrics-storage
  memory_mode: "dbengine"  # The long-term metrics storage with efficient RAM and disk usage.
  page_cache_size: 64  # Determines the amount of RAM in MiB that is dedicated to caching Netdata metric values.
  dbengine_disk_space: 1024  # Determines the amount of disk space in MiB that is dedicated to storing Netdata metric values.




# PostgreSQL variables
postgresql_data_dir: "/var/lib/pgsql/{{ postgresql_version }}/data"  # You can specify custom data dir path
postgresql_wal_dir: ""  # custom WAL dir path (symlink will be created) [optional]
postgresql_conf_dir: "{{ postgresql_data_dir }}"
postgresql_bin_dir: "/usr/pgsql-{{ postgresql_version }}/bin"
postgresql_log_dir: "/var/log/postgresql"
postgresql_unix_socket_dir: "/var/run/postgresql"
postgresql_home_dir: "/var/lib/pgsql"

# stats_temp_directory (mount the statistics directory in tmpfs)
postgresql_stats_temp_directory_path: "/var/lib/pgsql_stats_tmp"  # or 'none'
postgresql_stats_temp_directory_size: "1024m"

postgresql_version_terse: "{{ postgresql_version | replace('.', '') }}"

# Repository
yum_repository: []
#  - name: "repo name"
#    description: "repo description"
#    baseurl: "https://my-repo.url"
#    gpgkey: "https://my-repo-key.url"
#    gpgcheck: "yes"

install_epel_repo: true  # or 'false' (installed from the package "epel-release-latest.noarch.rpm")
install_postgresql_repo: true  # or 'false' (installed from the package "pgdg-redhat-repo-latest.noarch.rpm")
install_scl_repo: true  # or 'false' (Redhat 7 family only)

# Packages (for yum repo)
os_specific_packages:
  RedHat-7:
    - python
    - python-devel
    - python-psycopg2
    - python-setuptools
    - libselinux-python
    - libsemanage-python
    - policycoreutils-python
  RedHat-8:
    - python2
    - python3-libselinux
    - python3-libsemanage
    - python3-policycoreutils
system_packages:
  - "{{ os_specific_packages[ansible_os_family ~ '-' ~ ansible_distribution_major_version] }}"
  - python3
  - python3-devel
  - python3-psycopg2
  - python3-setuptools
  - python3-pip
  - curl
  - less
  - sudo
  - vim
  - gcc
  - jq
  - iptables
  - acl

# The glibc-langpack package includes the basic information required to support the language in your applications.
# for RHEL version 8 (only)
glibc_langpack:
  - "glibc-langpack-en"
  - "glibc-langpack-ru"  # optional
#  - "glibc-langpack-de"

postgresql_packages:
  - postgresql{{ postgresql_version_terse }}
  - postgresql{{ postgresql_version_terse }}-server
  - postgresql{{ postgresql_version_terse }}-contrib
  - postgresql{{ postgresql_version_terse }}-devel
#  - pg_repack{{ postgresql_version_terse }}

# Extra packages
etcd_package_repo: "https://github.com/etcd-io/etcd/releases/download/{{ etcd_ver }}/etcd-{{ etcd_ver }}-linux-amd64.tar.gz"
wal_g_package_repo: "https://github.com/wal-g/wal-g/releases/download/{{ wal_g_ver }}/wal-g.linux-amd64.tar.gz"
vip_manager_package_repo: "https://github.com/cybertec-postgresql/vip-manager/releases/download/v{{ vip_manager_version }}/vip-manager-{{ vip_manager_version }}-1.x86_64.rpm"
# (if with_haproxy_load_balancing: true)
haproxy_installation_method: "rpm"  # (default)"rpm" or "src"
haproxy_install_repo: true  # or 'false' # only for RedHat/CentOS version 7.
# for RedHat/CentOS/OracleLinux 7 the haproxy version 1.8 (LTS) will be installed from the "rh-haproxy18" package from the Software Collections (SCL) repository.
# you can preload the haproxy rpm packages to your YUM repository (in this case specify "haproxy_install_repo: false").
confd_package_repo: "https://github.com/kelseyhightower/confd/releases/download/v0.16.0/confd-0.16.0-linux-amd64"

# You can also use your own repository for extra packages. You need to preload all the packages and change this URLs.
installation_method: "repo"  # (default)"repo" or "file"

# Patroni package will be installed from the pip repository (by default).
# You also have the option of choosing an patroni installation method using the rpm package.
patroni_installation_method: "pip"  # (default)"pip" or "rpm"

# (if patroni_installation_type: "pip")
# Packages from your repository will be used to install instead of the pip repository.
pip_package_repo: "https://bootstrap.pypa.io/get-pip.py"  # latest version pip3 for python3 (or use "pip-<version>.tar.gz").
patroni_pip_requirements_repo: []
#  - "http://my-repo.url/setuptools-41.2.0.zip"
#  - "http://my-repo.url/setuptools_scm-3.3.3.tar.gz"
#  - "http://my-repo.url/urllib3-1.24.3.tar.gz"
#  - "http://my-repo.url/boto-2.49.0.tar.gz" # (interfaces to Amazon Web Services)
#  - "http://my-repo.url/PyYAML-5.1.2.tar.gz"
#  - "http://my-repo.url/chardet-3.0.4.tar.gz"
#  - "http://my-repo.url/idna-2.8.tar.gz"
#  - "http://my-repo.url/certifi-2019.9.11.tar.gz"
#  - "http://my-repo.url/requests-2.22.0.tar.gz"
#  - "http://my-repo.url/six-1.12.0.tar.gz"
#  - "http://my-repo.url/kazoo-2.6.1.tar.gz"
#  - "http://my-repo.url/dnspython-1.16.0.zip"
#  - "http://my-repo.url/python-etcd-0.4.5.tar.gz"
#  - "http://my-repo.url/Click-7.0.tar.gz"
#  - "http://my-repo.url/prettytable-0.7.2.tar.gz"
#  - "http://my-repo.url/pytz-2019.2.tar.gz"
#  - "http://my-repo.url/tzlocal-2.0.0.tar.gz"
#  - "http://my-repo.url/wheel-0.33.6.tar.gz"
#  - "http://my-repo.url/python-dateutil-2.8.0.tar.gz"
#  - "http://my-repo.url/psutil-5.6.3.tar.gz"
#  - "http://my-repo.url/cdiff-1.0.tar.gz"
patroni_pip_package_repo: []
#  - "http://my-repo.url/patroni-1.6.0.tar.gz"

# (if patroni_installation_type: "rpm")
# You can preload the patroni rpm package to your YUM repository, or explicitly specify the path to the package in this variable:
patroni_rpm_package_repo: []
#  - "https://github.com/cybertec-postgresql/patroni-packaging/releases/download/1.6.5-1/patroni-1.6.5-1.rhel7.x86_64.rpm"  # (package for RHEL/CentOS 7)

patroni_pip_package_file:
  - "patroni-1.6.0.tar.gz"  # https://pypi.org/project/patroni/#files

# ( if patroni_installation_type: "rpm" and installation_method: "file" )
patroni_rpm_package_file: "patroni-1.6.0-1.rhel7.x86_64.rpm"  # (package for RHEL/CentOS 7) https://github.com/cybertec-postgresql/patroni-packaging/releases/

# additional packages
etcd_package_file: "etcd-v3.3.15-linux-amd64.tar.gz"  # https://github.com/etcd-io/etcd/releases
wal_g_package_file: "wal-g.linux-amd64.tar.gz"  # https://github.com/wal-g/wal-g/releases
confd_package_file: "confd-0.16.0-linux-amd64"  # https://github.com/kelseyhightower/confd/releases
# (optional) if haproxy_installation_method: 'src'
lua_src_file: "lua-5.3.5.tar.gz"  # https://www.lua.org/ftp/lua-5.3.5.tar.gz (required for build haproxy)

# ------------------------------------------------------------------------------------------------- #
# (optional) Specify additional rpm packages if required (for any installation_method)
# this packages will be installed before all other packages.
packages_from_file: []
#  - "python3-psycopg2-2.7.7-2.el7.x86_64.rpm"  # https://mirror.linux-ia64.org/epel/7/x86_64/Packages/p/  # (required for patroni rpm)
#  - "libyaml-0.1.4-11.el7_0.x86_64.rpm"  # (required for patroni rpm)
#  - "jq-1.5-1.el7.x86_64.rpm"  # https://mirror.linux-ia64.org/epel/7/x86_64/Packages/j/
#  - "other-package-name_1_amd64.rpm"
#  - ""

# ----------------------------------------------------------------------------------------------------------------------------------
# Attention! If you want to use the installation method "file".
# You need to independently determine all the necessary the dependencies of rpm packages for your version of the Linux distribution.
# ----------------------------------------------------------------------------------------------------------------------------------

# Proxy variables (optional) for download packages using a proxy server
proxy_env: {}
#  http_proxy: http://10.128.64.9:3128
#  https_proxy: http://10.128.64.9:3128

# -------------------------------------------

# Cluster variables
cluster_vip: ""  # ip address for client access to databases in the cluster (optional)
vip_interface: "enp0s3"  # interface name (ex. "ens32")

patroni_cluster_name: "postgres-cluster"  # specify the cluster name
patroni_install_version: "latest"  # or specific version (example 1.5.6)

patroni_superuser_username: "postgres"
patroni_superuser_password: "postgres-pass"  # please change password
patroni_replication_username: "replicator"
patroni_replication_password: "replicator-pass"  # please change password

synchronous_mode: false  # or 'true' for enable synchronous database replication
synchronous_mode_strict: false  # if 'true' then block all client writes to the master, when a synchronous replica is not available
synchronous_node_count: 1  # number of synchronous standby databases

# if dcs_exists: true and dcs_type: "etcd" - specify ip address your etcd cluster in the "patroni_etcd_hosts" variable
# example (use existing cluster of 3 nodes)
patroni_etcd_hosts: []
#  - { host: "10.128.64.140", port: "2379" }
#  - { host: "10.128.64.142", port: "2379" }
#  - { host: "10.128.64.143", port: "2379" }

# more options you can specify in the roles/patroni/templates/patroni.yml.j2
# https://patroni.readthedocs.io/en/latest/SETTINGS.html#etcd
# https://patroni.readthedocs.io/en/latest/SETTINGS.html#consul

# DNS servers (/etc/resolv.conf)
nameservers: []
#  - "8.8.8.8"  # example (Google Public DNS)
#  - "9.9.9.9"  # (Quad9 Public DNS)

# /etc/hosts (optional)
etc_hosts: []
#  - "10.128.64.143 pgbackrest.minio.local minio.local s3.eu-west-3.amazonaws.com"  # example (MinIO)
#  - ""

# Generate locale
# (except RHEL>=8,use glibc-langpack)
locale_gen:
  - {language_country: "en_US", encoding: "UTF-8"}
  - {language_country: "ru_RU", encoding: "UTF-8"}  # optional
#  - {language_country: "", encoding: ""}

# Set system locale (LANG,LC_ALL)
locale: "en_US.utf-8"

# Configure swap space (if not already exists)
swap_file_create: true  # or 'false'
swap_file_path: /swapfile
swap_file_size_mb: '2048'  # change this value for your system

# Kernel parameters
sysctl_set: true  # or 'false'
# these parameters for example! Specify kernel options for your system
sysctl_conf:
  etcd_cluster: []
  master: []
  replica: []
  postgres_cluster:
    - {name: "vm.overcommit_memory", value: "2"}
    - {name: "vm.swappiness", value: "1"}
    - {name: "vm.min_free_kbytes", value: "102400"}
    - {name: "vm.dirty_expire_centisecs", value: "1000"}
    - {name: "vm.dirty_background_bytes", value: "67108864"}
    - {name: "vm.dirty_bytes", value: "536870912"}
#    - {name: "vm.nr_hugepages", value: "9510"}  # example "9510"=18GB
    - {name: "vm.zone_reclaim_mode", value: "0"}
    - {name: "kernel.numa_balancing", value: "0"}
    - {name: "kernel.sched_migration_cost_ns", value: "5000000"}
    - {name: "kernel.sched_autogroup_enabled", value: "0"}
    - {name: "net.ipv4.ip_nonlocal_bind", value: "1"}
    - {name: "net.ipv4.ip_forward", value: "1"}
    - {name: "net.ipv4.ip_local_port_range", value: "10000 65535"}
    - {name: "net.netfilter.nf_conntrack_max", value: "1048576"}
    - {name: "net.core.netdev_max_backlog", value: "10000"}
    - {name: "net.ipv4.tcp_max_syn_backlog", value: "8192"}
    - {name: "net.core.somaxconn", value: "65535"}
    - {name: "net.ipv4.tcp_tw_reuse", value: "1"}
#    - {name: "", value: ""}
  balancers:
    - {name: "net.ipv4.ip_nonlocal_bind", value: "1"}
    - {name: "net.ipv4.ip_forward", value: "1"}
    - {name: "net.ipv4.ip_local_port_range", value: "10000 65535"}
    - {name: "net.netfilter.nf_conntrack_max", value: "1048576"}
    - {name: "net.core.netdev_max_backlog", value: "10000"}
    - {name: "net.ipv4.tcp_max_syn_backlog", value: "8192"}
    - {name: "net.core.somaxconn", value: "65535"}
    - {name: "net.ipv4.tcp_tw_reuse", value: "1"}
#    - {name: "", value: ""}


# Transparent Huge Pages
disable_thp: true  # or 'false'


# Max open file limit
set_limits: true  # or 'false'
limits_user: "postgres"
soft_nofile: 65536
hard_nofile: 200000


# SSH Keys (optional)
enable_ssh_key_based_authentication: false  # or 'true' for configure SSH Key-Based Authentication
ssh_key_user: "postgres"
ssh_key_state: "present"
ssh_known_hosts: "{{ groups['postgres_cluster'] }}"


# sudo
sudo_users:
  - name: "postgres"
    nopasswd: "yes"  # or "no" to require a password
    commands: "ALL"
#  - name: "joe" # other user (example)
#    nopasswd: "no"
#    commands: "/usr/bin/find, /usr/bin/less, /usr/bin/tail, /bin/kill"

# (optional) - Fetch files from the server in the "master" group. These files can later be copied to all servers.
fetch_files_from_master: []
#  - {src: "/etc/ssl/certs/ssl-cert-snakeoil.pem", dest: "files/ssl-cert-snakeoil.pem"}
#  - {src: "/etc/ssl/private/ssl-cert-snakeoil.key", dest: "files/ssl-cert-snakeoil.key"}
#  - {src: "/path/to/myfile", dest: "files/myfile"}

# (optional) - Copy this files to all servers in the cluster ("master" and "replica" groups)
copy_files_to_all_server: []
#  - {src: "files/ssl-cert-snakeoil.pem", dest: "/etc/ssl/certs/ssl-cert-snakeoil.pem", owner: "postgres", group: "postgres", mode: "0644"}
#  - {src: "files/ssl-cert-snakeoil.key", dest: "/etc/ssl/private/ssl-cert-snakeoil.key", owner: "postgres", group: "postgres", mode: "0600"}
#  - {src: "files/myfile", dest: "/path/to/myfile", owner: "postgres", group: "postgres", mode: "0640"}

#Prometheus
prometheus:
  user: prometheus
  group: prometheus
  version: 2.32.1
  remove_src: true
  dir: "/etc/prometheus"
  targets_dir: "/etc/prometheus/targets"
  alerts_dir: "/etc/prometheus/alerts"
  bin_sources: "/data/prometheus-sources"
  download_dir: "/data/downloads"
  log: /var/log/prometheus/prometheus.log
  storage: /home/prometheus/data
  retention_time: 7d

# Grafana
grafana_defaults:
  service: grafana-server.service
  group: grafana
  user: grafana
  dir: "/etc/grafana"
  log: /var/log/grafana/grafana.log
  log_dir: /var/log/grafana/
  lib_dir: /var/lib/grafana/
  download_dir: /data/downloads
  rpm: grafana-8.2.0-1.x86_64
  smtp_host: smtp.yandex.com
  smtp_port: 465
  admin_user: admin
  admin_password: admin1234
  plugins_list:
    - "vertamedia-clickhouse-datasource"
    - "grafana-clock-panel"
    - "grafana-piechart-panel"
    - "flant-statusmap-panel"
  plugins_dir: /var/lib/grafana/plugins




